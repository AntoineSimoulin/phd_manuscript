\setchapterstyle{kao}
\setchapterpreamble[u]{\margintoc}
\chapter{Training sentence embeddings}
\labch{training}

\cleanchapterquote{Language is the most interesting manifestation of intelligence. Visual comprehension is something that many animals also have. In some cases, it is even better than that of humans. Chimpanzees also understand feelings and social contexts. But no other living being has such a complex language as we do. And language links all other manifestations of intelligence, because I can talk about what I see, feel and think and how I act.}{Richard Socher}{Head of research department at Salesforce}

\section{Training objective}

Proxy objective: classifying sentence pairs. Like the formal definition of meaning. Entailment, relatedness, sentence order, discourse relations, paraphrase identification. 

\section{Model architectures}
\labsec{training:architectures}

Structure of models, the role of structure. How do the requirement for syntax and word individual sense translate into neural models.

Artificial neural networks consist of connected units called neurons. Neurons define a vector space transformation based on linear algebra operators and nonlinear activation functions. Neural networks typically contain a very large number of neurons, which may be arranged into layers. Neurons—and by extension layers—are inter-connected: they receive input from their inner connections and send their output to their outer connections. Each layer has its own inner structure and connection pattern. The collection of layers and their connections forms a directed \textit{computational graph}. 